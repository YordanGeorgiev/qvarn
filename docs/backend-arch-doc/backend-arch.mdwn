---
title: Unified Resource API Backend Architecture
author: Suomen Tilaajavastuu Oy
date: UNRELEASED GIT VERSION
...


Introduction
============

This document describes the **implementation architecture** of the
**Unified Resource API**. The API is described in its own document.
This document covers the API implementation ("the backend") only, and
the reader is expected to understand the API already.

This document does not go into details of how each piece of
functionality is implemented, and instead concentrates on the overall
system structure. An architecture design exists to provide convenient
boxes into which functionality can be implemented, and defines how the
boxes interact with each other and with the outside world, but does
not go into much detail of what happens inside the boxes.


Design considerations
=====================

At the time of writing, there is no clear set of requirements for the
system. However, at least the following architectural requirements
exist:

* The services must be **scalable**. We expect to expand the company's
  services to many new countries and industries, leading to a much
  larger workload. The technical implementation of the services must
  not become a bottleneck when the number of users, and the amount of
  data, grows by up to several orders of magnitude.

* The services must be **highly available**. With more users, and more
  industries, we cannot afford to have the technical services be down
  so much that it affects a large number of users, or affects users
  frequently.

* The services must be **reliable**. Users should not be able to
  accidentally (or maliciously, but see below) be able to introduce
  errors to the stored data, or cause any part of the services to
  misbehave.

* The services must be **secure**. The more users we have, the more
  data we gather, the more attractive we will be to attackers. Our
  services must not succumb to attacks.

* The implementation of the services must be **adaptable** to changes
  imposed by the universe. Some of the functionality of the services
  is effectively specified by legislation, and that will change. We
  must be able to make reasonable functional changes easily, quickly,
  and without undue effort.

* The implementation of the services must be **verifiable**. We must
  be able to repeatedly and frequently check they work as expected and
  specified.

* The implementation and its use must be **auditable**. The system
  must keep track of who did what, and when.


Backend architecture
====================

![Backend architecture](backend-arch.eps)

This chapter describes the architecture of the API backend.

Overview
--------

The API backend is reactive: it only ever does something when
triggered by an HTTP request from an API client. The API provides
access to a data store, and any business logic or other data
processing happens in API clients. This includes regular actions, such
as retrieving data from external databases: the actual retrieval will
be implemented as an external application, which injects any new data
via the API using HTTP requests. Likewise, daily report generation is
triggered by an external application.

The API backend implementation is split into several independent
components, which get implemented as separate programs with their own
persistent storage, and which provide clearly defined, highly
constrained interfaces.

The components are:

* The **load balancer** redirects HTTP requests from API clients to
  instances of components. This is the only component that is visible
  to the world outside the backend.

* The **RESTful resource components** implement one top-level resource
  each (`/persons`, `/orgs`, `/version`). Each of these components has
  its own persistent storage (if it needs any storage), which is only
  accessed (read or write) by that component. The components may share
  significant amounts of code.

* The **write-only and read-only databases**: Database access for each
  resource component is split into write-only operations and read-only
  operations. This allows us to later easily replicate the database
  across multiple servers, even if we don't do that yet. The
  write-only access goes via one internal interface.

* An **identity management server** handles authentication of users
  and applications, and stores authorization data centrally.

All of the above components run on the same host, for now. We will
later change it so that the load balancer runs on one host, and the
resource components each on their own host. Further, we'll have at
least two load balancers, and at least two of each type of resource
component. We'll use DNS round-robin to balance traffic between the
load balancers. All load balancers will know about all resource
components.


Justification
-------------

In this architecture, the only non-replicated component is the
write-only databases. This enables **scalability** and **high
availability**.

If and when the write-only databases become a bottleneck, we will
investigate other approaches than doing all writes to a single
database.


Inter-component communication
-----------------------------

The resource components do not communicate with each other. However,
external applications, e.g., for producing reports, may need to
trigger updates of one resource when another resource has changed.
This is done using a notification feature in the API.


Authentication and authorisation
--------------------------------

We use the [Gluu][] software as the identity manager, and use
[OpenID Connect][] and [OAuth2][] as protocols. In addition, Gluu
supports the [SAML 2.0][] protocol for using selected external
identity providers to allow users to login with the credentials of
their home organisation.

[Gluu]: http://www.gluu.org/
[OpenID Connect]: https://en.wikipedia.org/wiki/OpenID_Connect
[OAuth2]: https://en.wikipedia.org/wiki/OAuth
[SAML 2.0]: https://en.wikipedia.org/wiki/SAML_2.0

We hide the existence of Gluu behind API calls. The API clients only
interact directly with our system, and we use reverse proxying for the
API calls that are redirected to Gluu. See the API document for a
description of the API calls and the authentication and authorisation
communication flows.

After a successful authentication, Gluu will provide the API client
with a [JWT][] token, digitally signed with a public key. The API
client provides this token in all further API requests in the
`Authorize` HTTP header. (For details, see API document.)

[JWT]: https://en.wikipedia.org/wiki/JSON_Web_Token

Authorization is done by the Gluu server providing a set of scopes
that specify which HTTP API calls the client is allowed to do. These
scopes are part of the JWT token. The API implementation validates the
token (checks its signature), and extracts the scopes from the token.
It then checks that the scopes allow the call in question. If that
fails, the API implementation returns a suitable HTTP error code.

A further level of authorisation is then done in the backend. For
example, a scope would say that the client is allowed to call `GET
/orgs`, but the actual return value should only include organisations
that the client is allowed to retrieve individually. Thus, if the
client can only access orgnisation id 123, but not 456, the result
should include 123, and not 
FIXME: How this is implemented is unclear.


Individual components
---------------------

Any component that needs persistent storage will handle it itself, by
having its own instance of a database server, or whatever storage it
needs. All instances of a component will share the same storage
instance. Note that this introduces a hidden, non-replicatable
sub-component, which may become a performance bottleneck.

Components could be implemented in a different programming languages,
different style, or using different frameworks or other programming
tools, or database engines, when that is justified and the benefits
overweigh the cost of additional variability. This is important also
so we can, in the future, more easily transition to other
implementation tools, should that become necessary.


Database storage
----------------

Currently, we use SQLite 3 for the database. This will eventually
change.


The load-balancing proxy
------------------------

The front of the backend is the load-balancing proxy. We use `haproxy`
as an existing, well-known solution for this.

The load-balancing proxy needs to know about the various instances of
each component. This is done by re-configuring the proxies when
component instances are deployed or destroyed.


Further detail
--------------

For further detail, please look at the source code directly.
